apiVersion: apps/v1
kind: Deployment
metadata:
  name: triton-custom
  namespace: vss
  labels:
    app: triton-custom
spec:
  replicas: 1
  selector:
    matchLabels:
      app: triton-custom
  template:
    metadata:
      labels:
        app: triton-custom
    spec:
      volumes:
      - name: workspace
        hostPath:
          #path: /home/bangpc/ai_gateway_triton/  
          path: /media/Data/bangpc/nfs_storage/triton_repo_new_dev
      - name: shm
        emptyDir:
          medium: Memory
        # nfs:
        #   server: 192.168.0.231
        #   path: /media/Data/bangpc/nfs_volume/triton_repo/fd_repo
        #   readOnly: false
      containers:
        - name: triton-custom
          ports:
          - containerPort: 8000
            name: http-triton
          - containerPort: 8001
            name: grpc-triton
          - containerPort: 8002
            name: metrics-triton
              #image: "triton_old:22.03"
          image: "tritonserver:22.08-py3-custom"
          volumeMounts:
          - mountPath: /workspace
            name: workspace
          - mountPath: /dev/shm
            name: shm
          command: ["/bin/sh", "-c"]
          args: ["/opt/tritonserver/bin/tritonserver --model-repository=/workspace/triton_repo --strict-model-config=false"]
            # resources:
            #   limits:
            #     nvidia.com/gpu: 1 # requesting 1 GPU
            # nodeSelector:
            #   kubernetes.io/hostname: aiserver-210

---

apiVersion: v1
kind: Service
metadata:
  name: triton-custom
  namespace: vss
  labels:
    app: triton-custom
spec:
  selector:
    app: triton-custom
  ports:
    - protocol: TCP
      port: 8000
      name: http
      targetPort: 8000
      nodePort: 31100
    - protocol: TCP
      port: 8001
      name: grpc
      targetPort: 8001
      nodePort: 31101
    - protocol: TCP
      port: 8002
      name: metrics
      targetPort: 8002
      nodePort: 32002
  type: NodePort 
  loadBalancerIP: 192.168.0.101
